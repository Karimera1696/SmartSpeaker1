import asyncio
import time
import queue
import numpy as np
import sounddevice as sd
import scipy.signal
import os

import wakeword, recorder, stt_openai, chat_openai, tts_openai, config

def set_volume(percent):
    os.system(f"amixer sset 'Master' {percent}%")

# ==== è¨­å®š ====
# ã—ãã„å€¤ã‚’ä»®ã«4000ã«è¨­å®š
set_volume(30)  # ã“ã“ã§éŸ³é‡ã‚’50%ã«è¨­å®š
NOISE_MARGIN = 2000
SILENCE_DURATION = 1.5  # è©±ã—å§‹ã‚ãŸå¾Œã®ç„¡éŸ³ç¶™ç¶šæ™‚é–“
MAX_RECORD_DURATION = 10.0  # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥å¾Œã®æœ€å¤§éŒ²éŸ³æ™‚é–“
NOISE_MEASURE_INTERVAL = 10.0  # 10ç§’ã”ã¨ã«æ¸¬å®š
NOISE_MEASURE_DURATION = 0.3  # æ¸¬å®šã¯0.3ç§’é–“
MIN_SPEECH_DURATION = 0.04    # ç™ºè©±é–‹å§‹åˆ¤å®šã«å¿…è¦ãªé€£ç¶šå…¥åŠ›æ™‚é–“(ç§’)
input_sample_rate = 44100
input_device = 1  # é©å®œå¤‰æ›´
output_device = None  # Noneãªã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼
q = queue.Queue()

def audio_callback(indata, frames, time, status):
    if status:
        print(f"âš ï¸ {status}")
    q.put(indata.copy())

def play_pcm(pcm_bytes, sample_rate=24000):
    audio = np.frombuffer(pcm_bytes, dtype=np.int16)
    sd.play(audio, samplerate=sample_rate, device=output_device)
    sd.wait()

def measure_noise_level(buffer, chunk_size, ww):
    """0.5ç§’é–“ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¸¬å®šã—ã€ãã®å¹³å‡ã‚’è¿”ã™"""
    levels = []
    start = time.time()
    while time.time() - start < NOISE_MEASURE_DURATION:
        if not q.empty():
            data = q.get().flatten()
            buffer = np.concatenate([buffer, data])
            while len(buffer) >= chunk_size:
                chunk = buffer[:chunk_size]
                buffer = buffer[chunk_size:]
                resampled = scipy.signal.resample(chunk, ww.engine.frame_length)
                resampled = np.round(resampled).astype(np.int16)
                level = np.max(np.abs(resampled))
                levels.append(level)
    if levels:
        avg = int(np.mean(levels))
    else:
        avg = 0
    return avg, buffer

def main():
    ww = wakeword.WakeWord(config.PICO_ACCESS_KEY, config.PPN_PATH, config.PV_MODEL)
    rec = recorder.Recorder()

    print("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰: ãƒã‚¤ã‚¯å…¥åŠ›ã§ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ»ä¼šè©±ã—ã¾ã™ã€‚Ctrl+Cã§çµ‚äº†ã€‚")

    triggered = False
    silence_start = None
    noise_level = 0
    SILENCE_THRESHOLD = 6000

    buffer = np.zeros(0, dtype='int16')
    chunk_size = int(input_sample_rate / ww.engine.sample_rate * ww.engine.frame_length)
    chunk_duration = chunk_size / input_sample_rate  # 1ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®æ™‚é–“(ç§’)

    with sd.InputStream(
        device=input_device,
        samplerate=input_sample_rate,
        channels=1,
        dtype='int16',
        blocksize=1024,
        callback=audio_callback
    ):
        print("ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ¸¬å®šä¸­...é™ã‹ã«ã—ã¦ãã ã•ã„")
        noise_level, buffer = measure_noise_level(buffer, chunk_size, ww)
        SILENCE_THRESHOLD = noise_level + NOISE_MARGIN
        print(f"ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_level}, ã—ãã„å€¤: {SILENCE_THRESHOLD}")
        last_noise_check = time.time()
        speech_buffer_accum = 0.0  # ç™ºè©±é–‹å§‹æ¤œå‡ºç”¨ãƒãƒƒãƒ•ã‚¡
        speech_started = False

        while True:
            if not triggered and time.time() - last_noise_check > 5.0:
                print("ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«å†æ¸¬å®šä¸­...é™ã‹ã«ã—ã¦ãã ã•ã„")
                noise_level, buffer = measure_noise_level(buffer, chunk_size, ww)
                SILENCE_THRESHOLD = noise_level + NOISE_MARGIN
                print(f"ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_level}, ã—ãã„å€¤: {SILENCE_THRESHOLD}")
                last_noise_check = time.time()

            while q.qsize() > 5:
                try:
                    q.get_nowait()
                except queue.Empty:
                    break

            if not q.empty():
                data = q.get().flatten()
                buffer = np.concatenate([buffer, data])

            while len(buffer) >= chunk_size:
                chunk = buffer[:chunk_size]
                buffer = buffer[chunk_size:]

                resampled = scipy.signal.resample(chunk, ww.engine.frame_length)
                resampled = np.round(resampled).astype(np.int16)
                level = np.max(np.abs(resampled))

                # --- ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º ---
                if not triggered and ww.engine.process(resampled) >= 0:
                    print("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼éŒ²éŸ³é–‹å§‹")
                    triggered = True
                    rec = recorder.Recorder()
                    silence_start = None
                    record_start = time.time()
                    speech_buffer_accum = 0.0
                    speech_started = False

                # --- éŒ²éŸ³ä¸­ ---
                if triggered:
                    rec.feed(resampled.tobytes(), triggered=True)
                    print(f"éŸ³é‡: {level}, ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {rec.size_bytes()}")  # ãƒ‡ãƒãƒƒã‚°ç”¨

                    # ç™ºè©±é–‹å§‹æ¤œçŸ¥ (ä¸€å®šæ™‚é–“ä»¥ä¸Šã®é€£ç¶šç™ºè©±ãŒå¿…è¦)
                    if not speech_started:
                        if level >= SILENCE_THRESHOLD:
                            speech_buffer_accum += chunk_duration
                        else:
                            speech_buffer_accum = 0.0
                        print(f"ç™ºè©±ãƒãƒƒãƒ•ã‚¡: {speech_buffer_accum:.2f}s")  # DEBUG
                        if speech_buffer_accum >= MIN_SPEECH_DURATION:
                            speech_started = True
                            print(f"ğŸ—£ï¸ ç™ºè©±é–‹å§‹æ¤œçŸ¥: {speech_buffer_accum:.2f}s")
                            silence_start = None
                        # ç„¡éŸ³çµ‚äº†åˆ¤å®šã¯ç™ºè©±é–‹å§‹å¾Œã«é©ç”¨
                        continue

                    # ç„¡éŸ³åˆ¤å®š
                    if level < SILENCE_THRESHOLD:
                        if silence_start is None:
                            silence_start = time.time()
                        elif time.time() - silence_start > SILENCE_DURATION:
                            print("éŒ²éŸ³çµ‚äº†ï¼ˆç„¡éŸ³ï¼‰ã€å‡¦ç†é–‹å§‹")
                            triggered = False
                            wav = rec.stop_and_dump()
                            print("STT...")
                            prompt = asyncio.run(stt_openai.speech_to_text(wav))
                            print("[STT]", prompt)
                            print("Chat...")
                            answer = asyncio.run(chat_openai.chat(prompt))
                            print("[Chat]", answer)
                            print("TTS...")
                            pcm24k = asyncio.run(tts_openai.text_to_speech(answer))
                            print("å†ç”Ÿã—ã¾ã™...")
                            play_pcm(pcm24k)
                            print("ä¼šè©±çµ‚äº†ã€‚ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å¾…æ©Ÿä¸­ã€‚")
                            silence_start = None
                            continue
                    else:
                        silence_start = None  # éŸ³ãŒã‚ã‚Œã°ãƒªã‚»ãƒƒãƒˆ

                    # æœ€å¤§éŒ²éŸ³æ™‚é–“
                    if time.time() - record_start > MAX_RECORD_DURATION:
                        print("éŒ²éŸ³çµ‚äº†ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰ã€å‡¦ç†é–‹å§‹")
                        triggered = False
                        wav = rec.stop_and_dump()
                        print("STT...")
                        prompt = asyncio.run(stt_openai.speech_to_text(wav))
                        print("[STT]", prompt)
                        print("Chat...")
                        answer = asyncio.run(chat_openai.chat(prompt))
                        print("[Chat]", answer)
                        print("TTS...")
                        pcm24k = asyncio.run(tts_openai.text_to_speech(answer))
                        print("å†ç”Ÿã—ã¾ã™...")
                        play_pcm(pcm24k)
                        print("ä¼šè©±çµ‚äº†ã€‚ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å¾…æ©Ÿä¸­ã€‚")
                        silence_start = None
                        continue

            time.sleep(0.001)

if __name__ == "__main__":
    main()